{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movie_day14_df = pd.read_csv('./14data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieInfo.json?key=0f56b7a37c358fa8fd15a4ffe5f78ab3&movieCd=20164168\n",
      "2910\r"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import random\n",
    "\n",
    "page_type = \"movie\" #\n",
    "search_type = \"searchMovieInfo\"\n",
    "return_type = \"json\"\n",
    "\n",
    "key_list=[\n",
    "          'a0c311535c77ebdb3bab229d4955a54a',\n",
    "          '797849ae4ee295a5b81f0b5628e37931',\n",
    "          '206a3a64108e08359f4de77e77de1c4d',\n",
    "          '0f56b7a37c358fa8fd15a4ffe5f78ab3',\n",
    "          '16cc45cd8569a777e530e4c26e2c474f'\n",
    "         ]\n",
    "base = \"http://www.kobis.or.kr/kobisopenapi/webservice/rest/\"\n",
    "\n",
    "missing_movie_df = pd.DataFrame(columns=['movieNm','movie_code','nations','distribution','rate','genre','director','actor','cast'])\n",
    "row = 0\n",
    "\n",
    "for movie_code in movie_day14_df['movie_code']:\n",
    "    try:\n",
    "        row+=1\n",
    "        param = \"&movieCd=%s\" % movie_code\n",
    "\n",
    "        request_token = page_type + \"/\" + search_type + \".\" + return_type + \"?key=\" + random.choice(key_list)\n",
    "\n",
    "        full_url = base + request_token+ param\n",
    "\n",
    "        rep = requests.get(full_url)\n",
    "\n",
    "        movie_data = rep.json()\n",
    "\n",
    "        ##국적값 nations\n",
    "        temp = []\n",
    "        for item in movie_data[\"movieInfoResult\"][\"movieInfo\"][\"nations\"]:\n",
    "            temp.append(str(item.get(\"nationNm\")))\n",
    "            nations = \"|\".join(temp)\n",
    "\n",
    "        ##장르값 genres\n",
    "        temp = []\n",
    "        for item in movie_data[\"movieInfoResult\"][\"movieInfo\"][\"genres\"]:\n",
    "            temp.append(str(item.get(\"genreNm\")))\n",
    "            genre = \"|\".join(temp)\n",
    "\n",
    "        ##배우, 캐스트\n",
    "        temp = []\n",
    "        cast = []\n",
    "        for item in movie_data[\"movieInfoResult\"][\"movieInfo\"][\"actors\"]:\n",
    "            temp.append(str(item.get(\"peopleNm\")))\n",
    "            cast.append(str(item.get(\"cast\")))\n",
    "            cast = list(filter(None, cast))\n",
    "            actor_name = \"|\".join(temp)\n",
    "            cast_name = \"|\".join(cast)\n",
    "\n",
    "        ##감독값 director_name\n",
    "        temp = []\n",
    "        for item in movie_data[\"movieInfoResult\"][\"movieInfo\"][\"directors\"]:\n",
    "            temp.append(str(item.get(\"peopleNm\")))\n",
    "            director_name = \"|\".join(temp)\n",
    "\n",
    "        temp = []\n",
    "        for item in movie_data[\"movieInfoResult\"][\"movieInfo\"][\"companys\"]:\n",
    "            if str(item.get(\"companyPartNm\")) == \"배급사\":\n",
    "                temp.append(str(item.get(\"companyNm\")))\n",
    "            distribution = \"|\".join(temp)\n",
    "\n",
    "        ##등급값 rate\n",
    "        temp = []\n",
    "        for item in movie_data[\"movieInfoResult\"][\"movieInfo\"][\"audits\"]:\n",
    "            temp.append(str(item.get(\"watchGradeNm\")))\n",
    "            rate = \"|\".join(temp)\n",
    "\n",
    "        missing_movie_df.loc[row] = [movie_data[\"movieInfoResult\"][\"movieInfo\"][\"movieNm\"],\n",
    "                                     movie_code,\n",
    "                                     nations,\n",
    "                                     distribution,\n",
    "                                     rate,\n",
    "                                     genre,\n",
    "                                     director_name,\n",
    "                                     actor_name,\n",
    "                                     cast_name\n",
    "                                     ]\n",
    "        print(row,end='\\r')\n",
    "    except:\n",
    "        print(full_url)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_movie_df.to_csv('./14_missing.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_movie_df = pd.read_csv('./14_missing.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df = 0\n",
    "actor_filmo = pd.DataFrame(columns=(\"actor_name\", \"filmo\",\"filmo_code\"))\n",
    "\n",
    "for index,row in missing_movie_df.iterrows():\n",
    "    peopleNm_list = [] ### 매번 비우면서\n",
    "    \n",
    "    if '|' in getattr(row,\"actor\"):\n",
    "        peopleNm_list = (getattr(row,\"actor\").split('|'))\n",
    "    else:\n",
    "        peopleNm_list.append(getattr(row,\"actor\"))\n",
    "        \n",
    "    filmoNames = getattr(row,\"movieNm\")\n",
    "    filmocode = getattr(row,\"movie_code\")\n",
    "    \n",
    "    for actor in peopleNm_list:\n",
    "        new_df+=1 ## actor_filmo row count\n",
    "        actor_filmo.loc[new_df] = [actor,filmoNames,filmocode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_code_bk = pd.read_csv('./8actor_code_bak.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1706\n",
      "3328\n",
      "4802\n",
      "6466\n",
      "8083\n",
      "9520\n",
      "11033\n",
      "12717\n",
      "14382\n",
      "15602\n",
      "17100\n",
      "Wall time: 12min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import parse\n",
    "import pandas as pd\n",
    "import html5lib\n",
    "import re\n",
    "import time\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import lxml\n",
    "from aiohttp import ClientSession\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "\n",
    "async def fetch(link,peopleNm,filmo,index):\n",
    "    async with ClientSession() as session:\n",
    "        async with session.get(link) as response:\n",
    "            html = await response.read()\n",
    "            try:\n",
    "                soup = BeautifulSoup(html,\"lxml\")\n",
    "                td = soup.find('td', class_='ellipsis')\n",
    "                link = td.find('a')['onclick']\n",
    "                code = int(re.search(r'\\d+', link).group()) ## 코드(숫자)만 걸러내기\n",
    "                total_actor_code_df.loc[index] = [peopleNm,filmo,code]\n",
    "            except Exception as e: \n",
    "                pass\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    count = 1\n",
    "    length = 300\n",
    "    tasks = []\n",
    "    loop = asyncio.get_event_loop()\n",
    "    \n",
    "    total_actor_code_df = pd.DataFrame(columns=['actor_name', 'filmo','filmo_code','code'])\n",
    "    \n",
    "    for index, row in actor_filmo.iterrows():\n",
    "        \n",
    "        peopleNm = getattr(row,\"actor_name\")\n",
    "        filmo = getattr(row,\"filmo\")\n",
    "        filmocode = getattr(row,\"filmo_code\")\n",
    "        \n",
    "        if any(actor_code_bk['filmo'][actor_code_bk['actor_name']==peopleNm] == filmo):\n",
    "            total_actor_code_df.loc[index] = [peopleNm,\n",
    "                                              filmo,\n",
    "                                              filmocode,\n",
    "                                              actor_code_bk['code'][actor_code_bk['filmo']==filmo][actor_code_bk['actor_name']==peopleNm].item()\n",
    "                                             ]\n",
    "        else:\n",
    "            peopleNm_parse = parse.quote(peopleNm)\n",
    "            filmo_parse = parse.quote(filmo)\n",
    "\n",
    "            param = \"sPeopleNm=%s&sMovName=%s\" % (peopleNm_parse,filmo_parse)\n",
    "\n",
    "            url1 = \"http://www.kobis.or.kr/kobis/business/mast/peop/searchPeopleList.do?\"\n",
    "\n",
    "            link = url1 + param\n",
    "\n",
    "            task = asyncio.ensure_future(fetch(link,peopleNm,filmo,index))\n",
    "            tasks.append(task)\n",
    "\n",
    "            if count == length: ## Task 300개 채우면\n",
    "                print(index)\n",
    "                loop.run_until_complete(asyncio.wait(tasks))\n",
    "                tasks=[]\n",
    "                length+= 300\n",
    "                \n",
    "            count+=1\n",
    "\n",
    "        if index == len(actor_filmo): ## 나머지 Task 채우기\n",
    "            loop.run_until_complete(asyncio.wait(tasks))\n",
    "            tasks = []\n",
    "            loop.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_actor_code_df.to_csv('./14act_code.txt', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "total_actor_code_df = pd.read_csv('./14act_code.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "600\n",
      "900\n",
      "1200\n",
      "1500\n",
      "1800\n",
      "2100\n",
      "2400\n",
      "2700\n",
      "3000\n",
      "3300\n",
      "3600\n",
      "3900\n",
      "4200\n",
      "4500\n",
      "4800\n",
      "5100\n",
      "5400\n",
      "5700\n",
      "6000\n",
      "6300\n",
      "6600\n",
      "6900\n",
      "7200\n",
      "7500\n",
      "7800\n",
      "8100\n",
      "8400\n",
      "8700\n",
      "9000\n",
      "9300\n",
      "9600\n",
      "9900\n",
      "10200\n",
      "10500\n",
      "10800\n",
      "11100\n",
      "11400\n",
      "11700\n",
      "12000\n",
      "12300\n",
      "12600\n",
      "12900\n",
      "13200\n",
      "13500\n",
      "13800\n",
      "14100\n",
      "14400\n",
      "Wall time: 1h 30min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import lxml\n",
    "from aiohttp import ClientSession\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "async def fetch(link,director_code,filmo_name,index,movie_code):\n",
    "    async with ClientSession() as session:\n",
    "        async with session.get(link) as response:\n",
    "            html = await response.read()\n",
    "            \n",
    "            soup = BeautifulSoup(html,\"lxml\")\n",
    "\n",
    "            tbody = soup.findAll('em', class_='tl')\n",
    "\n",
    "            result = []\n",
    "\n",
    "            for page in soup.find_all('p',class_='pageList pmt2'):\n",
    "                page_num = list(page.strings)\n",
    "                page_result = [i for i in page_num if i != '\\n']\n",
    "                \n",
    "            for etcParam in page_result:\n",
    "            \n",
    "                url2 = \"http://www.kobis.or.kr/kobis/business/mast/peop/searchPeopleDtl.do?\"\n",
    "\n",
    "                param = \"code=%s&sType=filmo&etcParam=%s\"  % (director_code,etcParam)\n",
    "\n",
    "                link = url2+param\n",
    "\n",
    "                average = await get(link,filmo_name,result)\n",
    "                                \n",
    "                director_average_df.loc[index] = [director_code,\n",
    "                                                  filmo_name,\n",
    "                                                  movie_code,\n",
    "                                                  average\n",
    "                                                 ]\n",
    "async def get(link,filmo_name,result):\n",
    "    async with ClientSession() as session:\n",
    "        async with session.get(link) as response:\n",
    "            \n",
    "            html = await response.read()\n",
    "            \n",
    "            soup = BeautifulSoup(html,\"lxml\")\n",
    "\n",
    "            tr_tag = []\n",
    "            real_tag = []\n",
    "            for count in soup.findAll('dl'):\n",
    "                if any(filmo_name in s for s in list(count.strings)):\n",
    "                    pass\n",
    "                elif any('주연' in x for x in list(count.strings)):\n",
    "    #                 else:\n",
    "                    tr_tag = tr_tag + list(count.strings)\n",
    "\n",
    "            for elem in range(0, len(tr_tag)) :\n",
    "                if tr_tag[elem] == '[공식통계]':\n",
    "                    real_tag.append(tr_tag[elem+3])\n",
    "\n",
    "            real_tag = [w.replace('명','') for w in real_tag] ## 명 없애기\n",
    "            real_tag = [w.replace(',','') for w in real_tag] ## , 없애기\n",
    "    #             real_tag = [w.replace('','0') for w in real_tag] ## , 없애기\n",
    "            real_tag = list(filter(None, real_tag))    ## 빈값 지우기\n",
    "            real_tag = list(map(int,real_tag))\n",
    "\n",
    "            result.extend(real_tag)\n",
    "\n",
    "            return int(average(result))\n",
    "\n",
    "def average(values):\n",
    "    if len(values) == 0:\n",
    "        return 0\n",
    "    return sum(values, 0.0) / len(values)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    count = 1\n",
    "    length = 300\n",
    "    tasks = []\n",
    "    last = 0\n",
    "    director_average_df = pd.DataFrame(columns=['code','filmo','movie_code','average_audience'])\n",
    "    \n",
    "    loop_director = asyncio.get_event_loop()\n",
    "    \n",
    "    for index,row in total_actor_code_df.iterrows():\n",
    "        filmo_name = getattr(row,'filmo')\n",
    "        director_code = getattr(row,'code')\n",
    "        movie_code = getattr(row,'filmo_code')\n",
    "        \n",
    "        param = \"code=%s&sType=filmo\"  % (director_code)\n",
    "        \n",
    "        url1 = \"http://www.kobis.or.kr/kobis/business/mast/peop/searchPeopleDtl.do?\"\n",
    "        \n",
    "        link = url1 + param\n",
    "        \n",
    "        task = asyncio.ensure_future(fetch(link,director_code,filmo_name,index,movie_code))\n",
    "        tasks.append(task)\n",
    "        \n",
    "        if index == length:\n",
    "            print(index)\n",
    "            loop_director.run_until_complete(asyncio.wait(tasks))\n",
    "            tasks = []\n",
    "            length += 300\n",
    "            \n",
    "        if index == len(total_actor_code_df):\n",
    "            loop_director.run_until_complete(asyncio.wait(tasks))\n",
    "            tasks = []\n",
    "            loop_director.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_average_df.to_csv('./14actor_average.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정글번치 : 빙산으로의 귀환 215\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "정글번치 : 빙산으로의 귀환 220\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "벤다 빌릴리 223\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "벤다 빌릴리 271\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "슈퍼미니 611\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "슈퍼미니 620\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "드래곤 기사단 637\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "드래곤 기사단 713\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "숲의 전설 787\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "숲의 전설 791\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "지휘자를 위한 1분 1023\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "뉴타입 히어로 얏타맨 1037\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "지휘자를 위한 1분 1057\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "톰과 제리 아카데미 가다 1071\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "뉴타입 히어로 얏타맨 1089\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "톰과 제리 아카데미 가다 1116\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "아스테릭스: 신들의 전당 1211\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "비비안 마이어를 찾아서 1221\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "비비안 마이어를 찾아서 1231\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "다이빙벨: 진실은 침몰하지 않습니다 1241\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "다이빙벨: 진실은 침몰하지 않습니다 1250\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "아스테릭스: 신들의 전당 1300\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "리틀드래곤 코코넛 1329\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "극장판 요괴워치: 탄생의 비밀이다냥! 1364\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "리틀드래곤 코코넛 1425\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "극장판 요괴워치: 탄생의 비밀이다냥! 1435\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "숀더쉽 1449\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "빌리와 용감한 녀석들 3D 1455\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "숀더쉽 1479\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "빌리와 용감한 녀석들 3D 1491\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "거미의 땅 1704\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "거미의 땅 1748\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "다이노소어 어드벤처 : 백악기 공룡대백과 1950\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "다이노소어 어드벤처 : 백악기 공룡대백과 1976\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "다이노소어 어드벤처 : 백악기 공룡대백과 1983\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "앵그리버드 더 무비 1996\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "앵그리버드 더 무비 2017\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "제독 : 미힐 드 로이테르 2068\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "명탐정 코난: 순흑의 악몽 2071\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "명탐정 코난: 순흑의 악몽 2127\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "지상에서 영원으로 2153\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "지상에서 영원으로 2262\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "감바의 대모험 2292\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "감바의 대모험 2315\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "아브릴과 조작된 세계 2342\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "아브릴과 조작된 세계 2413\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "플라워 2615\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "메모리즈 2624\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "추격자: 침묵의 살인 2626\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "플라워 2644\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "메모리즈 2653\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "메모리즈 2655\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "추격자: 침묵의 살인 2713\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "나의 붉은고래 2750\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "나의 붉은고래 2809\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "판필로프 사단의 28 용사 2820\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "판필로프 사단의 28 용사 2841\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "빈센트 반 고흐 : 새로운 시선 2846\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "올 리브 올리브 2853\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "올 리브 올리브 2892\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "빈센트 반 고흐 : 새로운 시선 2895\n",
      "can only convert an array of size 1 to a Python scalar\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movie_day14_df = pd.read_csv('./14data.csv', encoding='utf-8')\n",
    "\n",
    "final_df = pd.read_csv('./14actor_average.csv', encoding='euc-kr')\n",
    "\n",
    "missing_movie_df = pd.read_csv('./14_missing.csv')\n",
    "\n",
    "actor_sum = pd.DataFrame(columns=['movie_name',\n",
    "                                  'nation',\n",
    "                                  'distribution',\n",
    "                                  'director_average',\n",
    "                                  'actor_sum',\n",
    "                                  'rate',\n",
    "                                  'genre',\n",
    "                                  'release_date',\n",
    "                                  'day1_screen',\n",
    "                                  'day1_audience',\n",
    "                                  'day14_date',\n",
    "                                  'day14_audience'\n",
    "                                 ])\n",
    "\n",
    "for index,row in movie_day14_df.iterrows():\n",
    "    movie_name = getattr(row, 'movie_name')\n",
    "    movie_code = getattr(row, 'movie_code')\n",
    "    director_average = getattr(row,'director_average')\n",
    "    nation = getattr(row,'nation')\n",
    "    release_date = getattr(row,'release_date')\n",
    "    day1_screen = getattr(row,'day1_screen')\n",
    "    day1_audience = getattr(row,'day1_audience')\n",
    "    day15_date = getattr(row,'day14_date')\n",
    "    day15_audience = getattr(row,'day14_audience')\n",
    "    \n",
    "    movie_name = movie_name[1:]\n",
    "\n",
    "    try:\n",
    "        actor_sum.loc[index] = [\n",
    "                                movie_name,#                                 'movie_name',\n",
    "                                nation,#                                   'nation',\n",
    "                                missing_movie_df['distribution'][missing_movie_df['movie_code'] == movie_code].item(), ## 배급사\n",
    "                                director_average,#                                   'director_sum',\n",
    "                                sum(final_df['average_audience'][final_df['movie_code'] == movie_code]),#                 'actor_sum'\n",
    "                                missing_movie_df['rate'][missing_movie_df['movie_code'] == movie_code].item(),#         'rate',\n",
    "                                missing_movie_df['genre'][missing_movie_df['movie_code'] == movie_code].item(),#        'genre',\n",
    "                                release_date,#        'release_date'\n",
    "                                day1_screen,#          'day1_screen',\n",
    "                                day1_audience, # day1_audience\n",
    "                                day15_date,\n",
    "                                day15_audience\n",
    "                               ]\n",
    "    except Exception as e:\n",
    "        print(movie_name,index)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     프리비젼엔터테인먼트\n",
       "62    프리비젼엔터테인먼트\n",
       "Name: distribution, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_movie_df['distribution'][missing_movie_df['movie_code'] == movie_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_sum.to_csv('./14_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
